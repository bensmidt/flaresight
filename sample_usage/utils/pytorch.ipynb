{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/bensmidt/Documents/cai/cai/servers/server/src', '/Users/bensmidt/Documents/cai/cai/servers/sample_usage/utils', '/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python311.zip', '/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11', '/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload', '', '/Users/bensmidt/Documents/cai/cai/servers/env/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "SERVERS_PATH = os.path.abspath(\"../..\")\n",
    "SRC_PATH = os.path.join(SERVERS_PATH, \"src\")\n",
    "sys.path.insert(0, SRC_PATH)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.pytorch import max_magnitude_2d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_device_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Device 'cuda' is unavailable on this machine\n",
      "ERROR:root:Compute device needs to be one of '['cpu', 'cuda']', not 'invalid_device'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 'cuda' is unavailable on this machine\n",
      "Compute device needs to be one of '['cpu', 'cuda']', not 'invalid_device'.\n"
     ]
    }
   ],
   "source": [
    "from utils.pytorch import is_device_available\n",
    "\n",
    "is_device_available(\"cpu\", raise_error=True)\n",
    "print(is_device_available(\"cuda\", raise_error=False))\n",
    "print(is_device_available(\"invalid_device\", raise_error=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_magnitude_2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -5.1829,  -5.1229,   2.9350,  -0.9716, -18.8579, -11.9314,  -3.8780,\n",
      "         -20.2252,   7.2550,   7.5021,   6.5446,  -1.9982,  -2.5998,   0.8012,\n",
      "          -4.2550,  19.3421,   8.5582,   5.5754,  -6.5580,   4.3799],\n",
      "        [  3.4335,  -6.7928, -14.5057,  29.2592,  -3.2629,   8.3894,   9.5915,\n",
      "          14.1812,  14.9853,  -0.4454, -11.7673,  -7.1488,  -1.1566, -22.3829,\n",
      "           9.0551,   6.6807,  -0.4248,   7.4196,  -0.5576,   6.2312],\n",
      "        [  6.4326,   9.6645,  -1.1556,   1.0645,   8.7037,  -0.9072,   2.8020,\n",
      "           7.9839, -12.0294,  -1.6676,   5.0033,  -4.7102,   0.2721,  -6.9983,\n",
      "          40.0862,  -1.7312,  -5.4145, -11.1836,   4.8917,  -3.4572],\n",
      "        [ -2.8379,  -4.4316,  -0.7745,  -1.5686,  -6.7387,  -5.4110,   2.1406,\n",
      "          -5.8423, -13.0006,  -2.8179,  -0.1788,   2.3625,   3.6360,   8.8068,\n",
      "          -7.4161,   0.1768,  15.7661,  12.0708,  11.6466,   0.5200],\n",
      "        [  4.7026,  -8.3000,  -9.5331,  -6.0738,   1.9159,  15.5326,  -4.9627,\n",
      "           9.5777,  -4.5906, -12.7018,  22.0674,   1.9649,  15.1782,  -8.2468,\n",
      "           7.0450,   2.3023,  13.5871,  -0.0586, -16.5101,   2.5588],\n",
      "        [ -9.4909,   6.3634, -16.8813,  -5.7599,  10.7337,  -1.1132, -10.1722,\n",
      "          19.3616,   3.2787,  -9.4969,  13.9513,  -0.3336,  11.3076,  -0.6375,\n",
      "           6.1474,   1.4921,   9.1521,   1.2318,  11.3592,  -7.2003],\n",
      "        [ -5.1040,  -8.8081,   9.8349,  19.3284,   6.8628,  -7.5889,  -7.1017,\n",
      "         -13.6545,  -5.1493,  14.5193,   8.2723, -13.4910,   3.2366,  -6.2540,\n",
      "         -13.6408,  -2.7413,  -5.1583,   2.2752,   2.8752, -12.1828],\n",
      "        [  4.9343,   7.7658, -11.3467,  -5.5951,  -8.8310,  -9.0395,  17.3631,\n",
      "           2.7372,  -0.6517,  -1.4593,   4.0423, -12.4250,  -9.6169,   2.6935,\n",
      "           7.2590,   4.5434,   0.1365,   5.4135,  -5.1953,  -3.1324],\n",
      "        [ -1.3356,   3.4400,  -0.2515,   9.1500,   0.2997,  -6.7276,  -7.6428,\n",
      "           6.0520,  -2.6783,   0.6472,   1.1936,   7.3987,  13.9299,   4.1345,\n",
      "          -7.1586,  -9.0576,  -0.9410,   5.4111, -20.7339,   2.5992],\n",
      "        [ -2.2431,  11.3991,  12.5920,  -6.4122,   4.6229, -11.6258,  -2.8312,\n",
      "          18.8171, -14.1961,   0.2186,   2.7072,   3.6324,  -0.0938, -16.3223,\n",
      "          -3.7883,  10.8077,   7.8497,  -6.5717,  11.5716,  -4.1830],\n",
      "        [ 10.2413,  -4.0680,  -1.2014,   5.3398, -19.4636,  -8.4760,   3.0813,\n",
      "           3.3190,  -0.1731,  10.4031,   0.4085,   8.3886,  13.6283,   9.3950,\n",
      "           2.6016,   6.6419,   3.9017,  -0.2808,   3.9017,   9.4284],\n",
      "        [ -9.0827,  -9.5188,   0.6292,  -2.4334,   7.8350,   4.0879, -12.3243,\n",
      "           8.8716, -25.0320,  -2.9995,   3.5889,  -4.1973,  -3.2213,  15.2977,\n",
      "          12.7845,   4.3444,  -6.0535,  -0.2271, -15.8013,   3.4619],\n",
      "        [ -5.0632,   5.1471,   9.8505,   8.8824,   5.5597, -13.0548,   5.8113,\n",
      "          -6.5847,   0.1384,  -4.6112,   0.7701,   8.3801,  -5.7932,   7.6900,\n",
      "          11.3765, -30.7381,   0.2123,  -8.1478,  -8.9790,  -6.1385],\n",
      "        [ -2.7383,  -5.9923,  -8.2680,   3.2421,  -7.1333,   6.7989,  -8.4421,\n",
      "          -7.5616,   2.7968,   3.4050,   7.3501,  -2.5675,  -3.3349,   4.8248,\n",
      "          23.5912,  -5.9697,   8.4169,  -3.9467,   6.7119,  -3.4090]])\n",
      "tensor([ 10.2413,  11.3991, -16.8813,  29.2592, -19.4636,  15.5326,  17.3631,\n",
      "        -20.2252, -25.0320,  14.5193,  22.0674, -13.4910,  15.1782, -22.3829,\n",
      "         40.0862, -30.7381,  15.7661,  12.0708, -20.7339, -12.1828])\n",
      "tensor([-20.2252,  29.2592,  40.0862,  15.7661,  22.0674,  19.3616,  19.3284,\n",
      "         17.3631, -20.7339,  18.8171, -19.4636, -25.0320, -30.7381,  23.5912])\n"
     ]
    }
   ],
   "source": [
    "tensor = 10 * torch.randn(14, 20, dtype=torch.float32, device=\"cpu\")\n",
    "print(tensor)\n",
    "col_max = max_magnitude_2d(tensor, dim=0)\n",
    "print(col_max)\n",
    "row_max = max_magnitude_2d(tensor, dim=1)\n",
    "print(row_max)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.8667)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = 10 * torch.randn(14, dtype=torch.float32, device=\"cpu\")\n",
    "torch.linalg.norm(tensor, dim=0, ord=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cai",
   "language": "python",
   "name": "cai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cdfb9df01c38d8474546a072b1d6454d6e6248345ed55162d298781f385f1fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
